[{"title":"Rust笔记（一）","url":"/2025/07/10/Rust%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/","content":"开端\n参考Rust语言圣经(Rust Course)\nWindows上的Rust有两个版本MSVC和GNU，这里涉及到Microsoft C++ Build Tools(对应于MSVC版本，官方推荐)安装c++环境，或者MSYS2(对应于GNU版本)安装c++环境。\n\n其它安装的细节，以及在其它系统上的安装方式，请仔细阅读以上参考文档。\n可以使用命令rustup doc查看文档。\n在neovim里配置Rust开发环境\n\n安装rust-analyzer，这是Rust的LSP，需要对&quot;neovim/nvim-lspconfig&quot;进行配置。\n安装&quot;saecki/crates.nvim&quot;插件，这个插件用来提供依赖信息的增强支持。\n以上两者的配置如下plugins\\lsp.lua所示：\n\nreturn &#123;  &#123;    &quot;neovim/nvim-lspconfig&quot;,    opts = &#123;      inlay_hints = &#123; enable = true &#125;,      servers = &#123;        lua_ls = &#123;          settings = &#123;            Lua = &#123;              hint = &#123; enable = true &#125;,            &#125;,          &#125;,        &#125;,        [&quot;rust_analyzer&quot;] = &#123;          settings = &#123;            cargo = &#123; allFeatures = true &#125;,          &#125;,        &#125;,      &#125;,    &#125;,  &#125;,  &#123;    &quot;saecki/crates.nvim&quot;,    tag = &quot;stable&quot;,    config = function()      require(&quot;crates&quot;).setup(&#123;&#125;)    end,  &#125;,&#125;\n\n配置Rust调试，参考nvim-dap\n具体配置如plugin\\dap-rust.lua所示，需要修改codelldb.exe的路径：\n\nreturn &#123;  &quot;mfussenegger/nvim-dap&quot;,  -- 强烈推荐安装 nvim-dap-ui 来获得更好的调试 UI 体验  dependencies = &#123;    &quot;rcarriga/nvim-dap-ui&quot;,    &quot;nvim-neotest/nvim-nio&quot;,  &#125;,  config = function()    local dap = require(&quot;dap&quot;)    local dapui = require(&quot;dapui&quot;)    -- =================================================================    -- 1. 适配器定义 (Adapter Definition)    -- 这部分内容来自文档，并针对你的 v1.11.5 版本和 Windows 环境进行了适配    -- =================================================================    dap.adapters.codelldb = &#123;      type = &quot;server&quot;,      port = &quot;$&#123;port&#125;&quot;,      executable = &#123;        -- !!! 重要 !!! 请将这里的路径替换为你第一步中解压得到的真实路径。        -- 在 Lua 字符串中，即使是 Windows 路径，也建议使用正斜杠 &quot;/&quot;        command = &quot;C:/Users/weimo/AppData/Local/nvim/src/lldb/extension/adapter/codelldb.exe&quot;,        args = &#123; &quot;--port&quot;, &quot;$&#123;port&#125;&quot; &#125;,        -- 根据文档建议，在 Windows 上，你可能需要设置这个为 false        -- 这能确保 Neovim 退出时，codelldb 进程也能被正确关闭        detached = false,      &#125;,    &#125;    -- =================================================================    -- 2. 调试配置 (Debug Configuration)    -- 这部分告诉 nvim-dap 如何启动一个 Rust 程序的调试会话    -- =================================================================    dap.configurations.rust = &#123;      &#123;        name = &quot;Launch file (codelldb)&quot;,        type = &quot;codelldb&quot;, -- 必须与上面 dap.adapters 中定义的名字一致        request = &quot;launch&quot;,        program = function()          -- 启动时会提示你输入要调试的可执行文件的路径          -- 默认会帮你填充到 cargo 的 debug 输出目录          return vim.fn.input(&quot;Path to executable: &quot;, vim.fn.getcwd() .. &quot;/target/debug/&quot;, &quot;file&quot;)        end,        cwd = &quot;$&#123;workspaceFolder&#125;&quot;,        stopOnEntry = false,        -- 如果你的程序需要命令行参数，可以像下面这样添加        -- args = &#123; &quot;参数1&quot;, &quot;参数2&quot; &#125;,      &#125;,    &#125;    -- 如果你想 C 和 C++ 也使用这个配置，可以取消下面的注释    -- dap.configurations.c = dap.configurations.rust    -- dap.configurations.cpp = dap.configurations.rust    -- =================================================================    -- 3. DAP UI 配置和事件监听 (DAP UI Setup)    -- =================================================================    dapui.setup(&#123;      -- 布局配置: 定义了哪些窗口以及它们如何排列      layouts = &#123;        &#123;          elements = &#123;            -- 左侧窗口: 作用域和堆栈            &#123; id = &quot;scopes&quot;, size = 0.5 &#125;, -- 60% 的空间给变量作用域            &#123; id = &quot;stacks&quot;, size = 0.5 &#125;, -- 40% 的空间给调用堆栈          &#125;,          size = 80, -- 左侧边栏总共占用 40 列的宽度          position = &quot;left&quot;, -- 位置在左边        &#125;,        &#123;          elements = &#123;            -- 底部窗口: REPL 和 Console            &#123; id = &quot;repl&quot;, size = 0.5 &#125;, -- 50% 空间给 REPL            &#123; id = &quot;console&quot;, size = 0.5 &#125;, -- 50% 空间给程序输出          &#125;,          size = 20, -- 底部面板总共占用 10 行的高度          position = &quot;bottom&quot;, -- 位置在底部        &#125;,      &#125;,      -- 其他 UI 选项      floating = &#123;        max_height = nil, -- 浮动窗口的最大高度 (nil 表示无限制)        max_width = nil, -- 浮动窗口的最大宽度 (nil 表示无限制)        border = &quot;rounded&quot;, -- 浮动窗口边框样式        mappings = &#123;          close = &#123; &quot;q&quot;, &quot;&lt;Esc&gt;&quot; &#125;,        &#125;,      &#125;,      -- 在变量和监视窗口中显示值的具体实现      render = &#123;        max_value_lines = 1000, -- 显示值的最大行数      &#125;,    &#125;)    -- 在调试会话开始时自动打开 DAP UI，在结束时自动关闭    dap.listeners.after.event_initialized[&quot;dapui_config&quot;] = function()      dapui.open()    end    dap.listeners.before.event_terminated[&quot;dapui_config&quot;] = function()      dapui.close()    end    dap.listeners.before.event_exited[&quot;dapui_config&quot;] = function()      dapui.close()    end    -- =================================================================    -- 4. 快捷键 (Keymaps)    -- =================================================================    -- 基础调试快捷键 (使用 &lt;Leader&gt;d 前缀)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;db&quot;, dap.toggle_breakpoint, &#123; desc = &quot;[DAP] 切换断点&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;dc&quot;, dap.continue, &#123; desc = &quot;[DAP] 继续&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;do&quot;, dap.step_over, &#123; desc = &quot;[DAP] 单步跳过&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;di&quot;, dap.step_into, &#123; desc = &quot;[DAP] 单步进入&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;du&quot;, dap.step_out, &#123; desc = &quot;[DAP] 单步跳出&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;dr&quot;, dap.repl.open, &#123; desc = &quot;[DAP] 打开REPL&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;dl&quot;, dap.run_last, &#123; desc = &quot;[DAP] 运行上次配置&quot; &#125;)    vim.keymap.set(&#123; &quot;n&quot;, &quot;v&quot; &#125;, &quot;&lt;Leader&gt;dK&quot;, function()      dapui.eval()    end, &#123; desc = &quot;[DAP] 查看变量值&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;Leader&gt;dt&quot;, dap.terminate, &#123; desc = &quot;[DAP] 终止调试&quot; &#125;) -- 新增：终止调试    -- 传统 IDE 风格的 F 功能键 (冗余快捷键)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F5&gt;&quot;, dap.continue, &#123; desc = &quot;[DAP] 继续 (F5)&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F6&gt;&quot;, dap.pause, &#123; desc = &quot;[DAP] 暂停 (F6)&quot; &#125;) -- 新增：暂停功能    vim.keymap.set(&quot;n&quot;, &quot;&lt;F7&gt;&quot;, dap.step_out, &#123; desc = &quot;[DAP] 单步跳出 (F7)&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F8&gt;&quot;, dap.step_over, &#123; desc = &quot;[DAP] 单步跳过 (F8)&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F9&gt;&quot;, dap.toggle_breakpoint, &#123; desc = &quot;[DAP] 切换断点 (F9)&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F10&gt;&quot;, dap.step_into, &#123; desc = &quot;[DAP] 单步进入 (F10)&quot; &#125;)    vim.keymap.set(&quot;n&quot;, &quot;&lt;F12&gt;&quot;, function()      dapui.toggle()    end, &#123; desc = &quot;[DAP] 切换UI (F11)&quot; &#125;) -- 新增：方便地显示/隐藏UI    -- Shift + F* 快捷键    vim.keymap.set(&quot;n&quot;, &quot;&lt;S-F5&gt;&quot;, dap.terminate, &#123; desc = &quot;[DAP] 终止调试 (Shift+F5)&quot; &#125;) -- 对应VSCode的Shift+F5    vim.keymap.set(&quot;n&quot;, &quot;&lt;S-F8&gt;&quot;, function()      dap.run_to_cursor()    end, &#123; desc = &quot;[DAP] 运行到光标处 (Shift+F8)&quot; &#125;)  end,&#125;\n调试小技巧技巧\n这些快捷键与我的配置有关。\n\n不熟悉快捷键时可以pin一个快捷键截图。\n善用&lt;C+方向键调整窗口大小。\n&lt;leader&gt;dK可以查看光标位置的变量值。\n&lt;leader&gt;dr可以打开REPL，能够输入表达式并查看结果。\n\nCargo\n\ncargo项目的主目录结构是有要求的\n\nCargo.toml、src/在项目顶层。\n源代码全都在src/目录下。\n使用cargo new &lt;name&gt;命令创建新项目时，Cargo会自动创建Cargo.toml和src/main.rs文件。\n也可以使用cargo init &lt;name&gt;命令在当前目录初始化Cargo项目。\n\n\ncargo build命令会编译当前目录下的Cargo项目。\n\n编译结果会放在target/debug/目录下。\n同时会生成cargo.lock文件，记录依赖的版本信息。\n如果需要编译成发布版本，编译器会对代码进行优化，编译时间更长，但执行更快，可以使用cargo build --release，结果会放在target/release/目录下。j\n\n\ncargo run命令会编译并运行当前目录下的Cargo项目。\n\n但是如果项目没有修改，Cargo会跳过编译步骤，直接运行上次编译的结果。\n\n\ncargo check可以检查代码是否有错误，但不会生成可执行文件。\n\n它比cargo build快很多，这对于快速检查代码很有用，尤其是在开发过程中。\n\n\n[dependencies]，rand = &quot;0.9.1&quot;与rand = &quot;^0.9.1&quot;等价。\n\n^表示兼容版本，允许使用0.9.x版本。\n~表示兼容次版本，兼容范围可能与^一致或小一点。\n=表示精确版本，必须使用0.9.1。\n\n\ncargo update命令会更新依赖到最新的兼容版本。\n\n它会修改Cargo.lock文件，但不会修改Cargo.toml文件。\n\n\n\n发展\n数据\n变量与常量\n变量分成可变变量和不可变变量，都需要使用let声明。\n\n可变变量需要额外加上mut。\n\n常量使用const声明，必须指定类型。\n不可变变量与常量的区别\n\n\n不可变变量可以在运行时计算值，常量必须在编译时确定。\n不可变变量的特性：遮蔽，重新声明以覆盖。\n\nlet x = 5; // 不可变变量let x = 6; // 遮蔽，重新声明x为6\n\n常量的特性：全作用域可见：\n\n常量不管在何处声明都会作用域整个作用域，因为编译器会将常量名替换成值。\n同一个作用域内不能有同名的常量，原因如上，会冲突。\n内层作用域可以遮蔽外层作用域的常量，因为编译器会先在当前作用域匹配，找不到才会去外层作用域找。\n\nconst VALUE: u32 = 100_000;fn main() &#123;    println!(&quot;The value is: &#123;&#125;&quot;, VALUE);    const VALUE: u32 = 200_000;    &#123;        const VALUE: u32 = 300_000;        println!(&quot;The value is: &#123;&#125;&quot;, VALUE);    &#125;    println!(&quot;The value is: &#123;&#125;&quot;, VALUE);&#125;\n\n\n","categories":["笔记","Rust"],"tags":["笔记","编程语言","Rust","编程"]},{"title":"🕷️markdown语法笔记","url":"/2025/06/16/markdown%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/","content":"🕷️markdown语法笔记\n插入\n链接\n\n\n行内链接：[显示文本](链接地址 &quot;可选标题&quot;)\n\n\n引用式链接：\n[显示文本][链接标识][链接标识]: 链接地址 &quot;可选标题&quot;\n\n\n直接显示URL：&lt;https://markdown.org&gt;\n\n\n图片链接：[![图片替代文本](图片URL)](链接地址)\n\n\nemoji\n\n\nwin + .打开系统自带的emoji搜索\n\n\nemoji中文网等复制粘贴\n\n\n使用标签符号简码，需要安装Markdown Emoji插件，语法:joy:，效果:joy:。（此方法hexo不支持）\n\n\nfluid主题内置了一些图标，在配置about页的时候用到了，在文档里也可以如&lt;i class=&quot;iconfont icon-github-fill&quot;&gt;&lt;/i&gt;的方式使用，带链接的方式：\n\n[&lt;i class=&quot;iconfont icon-github-fill&quot;&gt;&lt;/i&gt;](https://github.com/weimoyo/weimoyo.github.io/tree/gh-source/source/snake)\n&lt;a href=&quot;https://github.com/weimoyo/weimoyo.github.io/tree/gh-source/source/snake)&quot; title=&quot;GitHub&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;i class=&quot;iconfont icon-github-fill&quot;&gt;&lt;/i&gt;&lt;/a&gt;\n\n\n\nfluid内置的图标的便捷使用方式，添加一个图标插件：\n\n\n在主题目录的scripts目录里创建一个icon.js，内容如下\n hexo.extend.tag.register(&#x27;icon&#x27;, function(args) &#123;const iconClass = args[0];const link = args[1];const tip = args[2];if (!iconClass) &#123;   return &#x27;&#x27;;&#125;// 智能判断基础类let baseClass = &#x27;iconfont&#x27;; // 默认是 iconfontif (iconClass.startsWith(&#x27;fa-&#x27;)) &#123;   baseClass = &#x27;fa&#x27;; // 如果以 fa- 开头，则是 Font Awesome&#125;let iconHtml = `&lt;i class=&quot;$&#123;baseClass&#125; $&#123;iconClass&#125;&quot;&gt;&lt;/i&gt;`;if (link) &#123;   const titleAttr = tip ? `title=&quot;$&#123;tip&#125;&quot;` : &#x27;&#x27;;   iconHtml = `&lt;a href=&quot;$&#123;link&#125;&quot; $&#123;titleAttr&#125; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;$&#123;iconHtml&#125;&lt;/a&gt;`;&#125;return iconHtml;&#125;);\n\n\n三种使用方式\n\n\n\n只显示图标&lt;i class=&quot;fa-brands fa-github&quot;&gt;&lt;/i&gt;:\n带链接的图标&lt;a href=&quot;https://github.com&quot;&gt;&lt;i class=&quot;fab fa-github&quot;&gt;&lt;/i&gt;&lt;/a&gt;:\n带链接和提示的图标&lt;a href=&quot;https://github.com/weimoyo&quot; title=&quot;https://github.com/weimoyo&quot;&gt;&lt;i class=&quot;fab fa-github&quot;&gt;&lt;/i&gt;&lt;/a&gt;:\n\n\n\n拼音\n编辑器： VSCode\n步骤：\n\n\n命令面板=&gt;Snippets: Configure Snippets=&gt;markdown\n\n\n使用预先准备的markdown.json\n\n\n在setting.json里配置，必须专门配置markdown格式。\n&quot;[markdown]&quot;: &#123;     &quot;editor.quickSuggestions&quot;: &#123;         &quot;other&quot;: &quot;on&quot;     &#125; &#125;\n\n\nMarkdown All in One等插件的设置对此没有影响。\n\n\n","categories":["笔记","markdown"],"tags":["markdown"]},{"title":"🐳docker使用笔记","url":"/2025/06/17/docker%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","content":"🐳docker使用笔记\nlinux\n运行Dockerfile时“permission denied”\n部分报错：ERROR: permission denied while trying to connect to the Docker daemon socket\n解决方法：\n\nsudo usermod -aG docker $USER\n需注销或重启才能生效，为的是让shell使用docker组的权限\n或为当前终端临时添加权限，newgrp docker\n可以用groups指令看当前shell是否拥有docker权限\n\n","categories":["笔记","docker"],"tags":["docker"]},{"title":"🐆neovim使用笔记","url":"/2025/06/20/neovim%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","content":"🐆neovim使用笔记\n光标移动\n\n基础： h、j、k、l对应←↓↑→，gg、G跳转到文档头、尾。\nword跳转： w、e跳转到后一个“word的开头、结尾”，b跳转到前一个“word的开头”。不含除_外的标点符号。\nWORD跳转：W、E跳转到后一个“WORD的开头、结尾”，B跳转到前一个“WORD的开头”。“WORD”以空格为单位。\n注：\n\n“word”的描述很繁琐，但是含义很简单，故不多赘述。\n以上快捷键都可以与数字搭配使用。\n基础移动会以方向的尽头终止，如100l若超过该行剩余字符数则会移动到该行末尾。\n但是，word跳转的语义是“上一个、下一个”，只要没有到文档头尾，就不会终止跳转。\n\n\n根据字符跳转：f、F分别表示后一个字符、前一个字符（行内）。例如2fs表示跳转到后面第二个&quot;s&quot;的位置。\n\n复制、粘贴、剪切\n\n\n基础： y &lt;motion&gt;复制，d &lt;motion&gt;删除，c &lt;motion&gt;删除并进入插入模式，p、P在光标的右侧、左侧粘贴。\n\n\n\n\n描述\n成员\n\n\n\n\ninclusive motion\n仅有顺序，包含边界\ne\n\n\nexclusive motion\n顺序，仅不包含结尾逆序，仅不包含开头\nw、lb、h\n\n\n\n\n文档头尾、一行的头尾都会有特殊，以上描述以移动的“预期”效果为基础，例如，文档最后一个word上再按w只会移动到该word的末尾，但是“预期”会移动到下一个的开头。故依然会包含整个word。\n表格里的开头、结尾是移动方向的头和尾，不是顺序方向。\n\n\n\n行级操作：\n\n\n\n命令\n效果\n\n\n\n\nyy\n复制一整行\n\n\ndd\n删除一整行\n\n\ny j/k\n包含当前行到目标行\n\n\nd j/k\n同理\n\n\np、P\n在下一行、上一行粘贴\n\n\n\n\n\ntext object操作： &lt;verb&gt; &lt;prep&gt; &lt;text object&gt;\n\n\nprep: innner，around\n\n\n常用文本对象\n\n\n\n文本对象\n作用范围\n示例命令\n效果\n\n\n\n\niw / aw\n单词（word）\nciw\n修改当前单词（不含空格）\n\n\niW / aW\n大单词（WORD，含标点）\ndiW\n删除当前大单词（如 “hello!”）\n\n\nis / as\n句子（sentence）\nvas\n选择当前句子\n\n\nip / ap\n段落（paragraph）\ndap\n删除当前段落（含空行）\n\n\ni&quot; / a&quot;\n双引号内内容\nyi&quot;\n复制引号内文本（不含引号）\n\n\ni' / a'\n单引号内内容\nci'\n修改单引号内文本\n\n\ni` / a`\n反引号内内容\ndi`\n删除反引号内代码\n\n\ni( / a(  (ib / ab)\n圆括号内内容\nci(\n修改括号内文本（不含括号）\n\n\ni[ / a[\n方括号内内容\nvi[\n选择方括号内文本\n\n\ni&#123; / a&#123;  (iB / aB)\n花括号内内容\ndi&#123;\n删除代码块内容（不含 {}）\n\n\nit / at\nXML/HTML 标签内容\ncit\n修改标签内文本（如 &lt;div&gt;内容&lt;/div&gt;）\n\n\ni&lt; / a&lt;\n尖括号内内容（如泛型）\ndi&lt;\n删除 &lt;T&gt; 内部内容\n\n\n\n\n\n\n\n其它常用命令、快捷键\n命令:e(dit)\n打开文件，相对路径、绝对路径都可以。\n自动补全\n\n&lt;C-n&gt;、&lt;C-p&gt;：在插入模式下，向前、向后自动补全。\n\n注释\n\nNormal模式下，使用gcc注释/取消注释当前行，gc注释/取消注释选中区域。\n\n悬浮文档\n\nNormal模式下，快捷键K可以查看光标下的函数、变量等的文档。\n打开悬浮文档后，可以使用&lt;C-f&gt;和&lt;C-b&gt;翻页。\n\n排版\n\n1./2./3.等有序列表的下层域需要缩进4个空格或者2个Tab。\n*/-/+等无序列表的下层域需要缩进2个空格或者1个Tab。\n\n","categories":["笔记","neovim"],"tags":["笔记","工具","终端","编辑器","neovim"]},{"title":"neovim插件记录、用法","url":"/2025/07/07/neovim%E6%8F%92%E4%BB%B6%E8%AE%B0%E5%BD%95%E3%80%81%E7%94%A8%E6%B3%95/","content":"bullets-vim\n功能：自动处理markdown中的列表序号。\n快捷键：\n\n\n\n按键\n模式\n功能\n\n\n\n\n&lt;cr&gt;\nINSERT\n换行并插入新的bullet\n\n\no\nNORMAL\n效果同上。\n\n\n&lt;C-cr&gt;\nINSERT\n仅换行\n\n\ngN\nNORMAL/VISUAL\n对光标所在列表(或者所选中的部分)重排序\n\n\n&gt;&gt;\nNORMAL\n缩进（同时调整编号，下皆同）\n\n\n&lt;C-t&gt;\nINSERT\n缩进\n\n\n&gt;\nViSUAL\n缩进\n\n\n&lt;&lt;\nNORMAL\n取消缩进\n\n\n&lt;C-d&gt;\nINSERT\n取消缩进\n\n\n&lt;\nVISUAL\n取消缩进\n\n\n\nrender-markdown\n功能：文档超详细，配置非常简单的markdown渲染插件。建议用它替代:LazyExtra里的markdown模块。\n\n标题图标、padding，高亮范围。\n代码块、callouts、链接图标。\n列表美化。\n等等。\n\n配置：详情见此链接\n要想舒舒服服编辑markdown文档还需要关闭拼写检查。\n\nlspsaga.nvim\n功能：提供了一组LSP增强功能，有原本nvim-lspconfig不包含的功能，也有做得更好的功能，也有原本就足够的功能，列举几个比较有用的：\n以下快捷键都来源于我的个人配置。\n\n\n\nHober: 本插件提供的悬浮信息窗口支持markdown渲染，快捷键是&lt;leader&gt;k。\n\n\nDiagnostic: 本插件提供了更丰富的诊断信息、可能的修复建议，以及光标、行、buff、工作区四个范围的诊断信息展示。\n\n\n\n功能\n快捷键\n\n\n\n\n上一个诊断信息\n[e\n\n\n下一个诊断信息\n]e\n\n\n光标位置的诊断信息\n&lt;leader&gt;dc\n\n\n光标所在行的诊断信息\n&lt;leader&gt;dl\n\n\n当前buff的诊断信息\n&lt;leader&gt;db\n\n\n当前工作区的诊断信息\n&lt;leader&gt;dw\n\n\n\n\n\nOutline: 按下&lt;C-o&gt;就可以打开文件的大纲，在大纲里按e可以跳转到对应位置。\n\n\nDefinition: 提供了一个定义悬浮窗，可以在里面编辑。\n\n\nflash.nvim\n这是一个LazyVim自带的插件，提供了极其好用的跳转功能，正如其名——FLASH。\n\n\n\n快捷键\n功能\n详细描述\n\n\n\n\ns\n搜索\n会给每个匹配项提供唯一标识，便于快速跳转\n\n\nS\ntreesitter搜索\n为每个层级的代码提供表示，便于快速选择整块的代码\n\n\nf/F\n向后、前字符跳转\n跳转到下一个/上一个字符\n\n\n;/,\n向后、前字符跳转\n使用前一次f/F的跳转模式\n\n\n[dyc]r\n闪现删除、复制、替换\n跳转到某个位置，完成操作后返回\n\n\n[dyc]R\ntreesitter闪现\n操作的单位是treesitter块，可以选择所有包含输入的字符的块\n\n\n&lt;C-s&gt;\n在/或者?搜索模式下开关\n会给每个匹配项提供唯一标识\n\n\n\n","categories":["笔记","neovim"],"tags":["笔记","工具","终端","编辑器","neovim"]},{"title":"neovim配置","url":"/2025/06/26/neovim%E9%85%8D%E7%BD%AE/","content":"前置\n配置文件在哪\n在neovim的命令模式输入:= vim.fn.stdpath(&quot;config&quot;)可以查看配置文件所在的目录，win下默认为~\\AppData\\Local\\nvim\\，在此目录下创建/修改主配置文件init.lua。\n模块化配置\n在init.lua的同级目录创建lua目录用以存放各个模块，继而使用require(&quot;module&quot;)引入名为module.lua的模块。\n建议： 在lua下再细分，例如基础的配置放到lua/core/下，拓展的配置放到lua/plugins/，引入的时候使用require(&quot;core.module&quot;)\n配置命令结构与一次性使用\n大多数配置命令都在vim.opt.之下，可以在命令模式使用例如:lua vim.opt.number = true对当前会话生效。\n配置项\n行号\n行号：vim.opt.number = true\n相对行号，便于快捷移动光标：vim.opt.relativenumber = true\n高亮、最大长度\nvim.opt.cursorline = true\nvim.opt.colorcolumn = &quot;80&quot;\ntab键行为\n改为插入空格：vim.opt.expandtab = true\n一个制表符显示为多少空格：vim.opt.tabstop = 4\n行首缩进长度，0表示与tabstop一致vim.opt.shiftwidth = 0\n配置更新相关\nvim.opt.autoread = true\n快捷键\napi: vim.keymap.set(mode, lhs, rhs, opts)。\n参数解释：\n\nmode: 快捷键生效模式（nvim的模式，&quot;n&quot;是normal模式，&quot;i&quot;是insert模式等），可以是单一模式（字符）也可以是组合模式（table）。\nlsh: 按键，其中，\n\nCtrl + a: &lt;C-a&gt;\nAlt + a: &lt;A-a&gt;\n\n\nrhs: 功能、映射的另一组按键、lua函数。\nopts: table，额外配置。\n\n插件\n","categories":["笔记","neovim"],"tags":["笔记","工具","终端","编辑器","neovim"]},{"title":"tts笔记","url":"/2025/07/16/tts%E7%AC%94%E8%AE%B0/","content":"index-tts\n官方文档非常详细，跟着来就行。建议工作流程：\n\n根据视频分镜写好稿子，注意特殊的词根据发音改写。\n将稿子提取成一整篇纯文字稿。\n使用index-tts的web端，转换整篇音频。\n放到pr里：对齐——切——对齐——切，即可。\n\n","categories":["实践指南","模型","tts"],"tags":["工具","实践","记录","tts","模型","配音"]},{"title":"《齐桓公伐楚》笔记","url":"/2025/06/19/%E3%80%8A%E9%BD%90%E6%A1%93%E5%85%AC%E4%BC%90%E6%A5%9A%E3%80%8B%E7%AC%94%E8%AE%B0/","content":"字、詞、表达記錄\n\n夾輔，輔佐。\n\n文章細節\n\n\n\n唯是風馬牛不相及也\n\n風，指發情。這句話的意思是，發情了的牲畜也碰不到一起。\n\n\n感悟\n","categories":["古代汉语","王力《古代汉语》笔记"],"tags":["古代汉语"]},{"title":"🐙x-cmd实践记录","url":"/2025/06/16/x-cmd%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/","content":"🐙x-cmd实践记录\n安装\n在powershell里安装，参考https://cn.x-cmd.com/start/powershell，只需要运行一条指令\n[System.Text.Encoding]::GetEncoding(&quot;utf-8&quot;).GetString($(Invoke-WebRequest -Uri &quot;https://get.x-cmd.com/x-cmd.ps1&quot;).RawContentStream.ToArray()) | Invoke-Expression\n更改主题\n\nx starship和x ohmyposh是两个主题模块，直接运行即可打开TUI交互选择。\n需要安装Nerd Fonts，否则图标无法正常显示。推荐选择（gemini 2.5 pro），\n\nFiraCode Nerd Font (非常流行，支持编程连字)\nJetBrains Mono Nerd Font (JetBrains IDE 的默认字体，非常清晰)\nMesloLGS NF (Powerlevel10k 主题官方推荐，兼容性极佳)\n\n\n效果，\n\n使用大模型，以Deepseek为例\n\nx deepseek init进行交互式配置，只需要提供key。\na:ds和a:dsr1使用\n\n对话a:ds &quot;用户提示词&quot;\na:ds -f 本地文件 &quot;用户提示词&quot;\n\n\na:ds -f 本地文件 &quot;用户提示词&quot; &gt;&gt; ds.md 2&gt;&amp;1可以输出到文档里，但是中文会乱码\n\n原因： PowerShell 7 查看 [System.Console]::OutputEncoding 的设置，发现是 GBK。于是，它用 GBK 的规则去“错误地”解码了这串 UTF-8 的字节流，在内存中得到了一堆乱码字符串。\n解决方法：\n\n修改powershell配置文件notepad $PROFILE如果不存在，新建New-Item -Path $PROFILE -ItemType File -Force\n在最后一行添加[System.Console]::OutputEncoding = [System.Text.Encoding]::UTF8\n使用管道a:ds -f 本地文件 &quot;用户提示词&quot; 2&gt;&amp;1 | Out-File -FilePath ds.md -Encoding utf8(尚未验证，不过原理可信)\n\n\n\n\n\n","categories":["实践指南","大东西","x-cmd"],"tags":["工具","终端","实践","记录","x-cmd"]},{"title":"pytest笔记（一）","url":"/2025/07/07/pytest%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/","content":"测试框架的作用\n\n用例发现、管理、执行。\n环境管理。\n测试报告。\n\npytest对比unittest\n\n需要手动安装、可以指定版本。\n代码风格不是Java而是Python。\n拥有更丰富的插件生态。\n完全兼容unittest。\n\n快速上手\n\n安装：uv add pytest -U\n启动方式：\n\n创建一个新文件添加pytest.main()。\npytest：自动发现当前目录下的所有测试文件，执行所有测试用例。\npytest test_*.py：执行指定的测试文件。\npytest test_*.py::test_func：执行指定的测试函数。\n\n\n\n用例\n\n\n结果种类\n\n\n\n缩写\n单词\n含义\n\n\n\n\n.\npassed\n通过\n\n\nF\nfailed\n失败（用例执行报错）\n\n\nE\nerror\n出错（fixture执行报错）\n\n\ns\nskipped\n跳过\n\n\nX\nxpassed\n预期外的通过（不符合预期）\n\n\nx\nxfailed\n预期内的失败（符合预期）\n\n\n\n\n\n用例发现规则和内容规则\n\n用例的发现规则——识别、加载用例的过程\n步骤：\n\n遍历当前目录及子目录下的所有文件，例外：venv、.*。\n打开test_开头或者_test结尾的python文件。\n遍历所有Test开头的类（不过该类并非是用例）。\n收集所有test_开头的函数或方法作为用例。\n\n\n用例的内容\n\n可调用（函数、方法、类、对象）。\ntest_开头。\n没有参数，但可以使用内置标记等手段使用参数。\n没有返回值（8.4版本后加入）。\n\n\n练习：对加法函数进行断言。注意本例里类和方法的命名方式，以及这种分组测试（封装）的设计思路。\n\ndef add(a, b):    &quot;&quot;&quot;Returns the sum of a and b.&quot;&quot;&quot;    return a + bclass TestAdd:    def test_int(self):        &quot;&quot;&quot;Tests the add function.&quot;&quot;&quot;        assert add(2, 3) == 5    def test_str(self):        &quot;&quot;&quot;Tests the add function with string inputs.&quot;&quot;&quot;        assert add(&quot;1&quot;, &quot;2&quot;) == &quot;12&quot;    def test_list(self):        &quot;&quot;&quot;Tests the add function with list inputs.&quot;&quot;&quot;        assert add([1, 2], [3, 4]) == [1, 2, 3, 4]\n\n\n\n\n配置框架\n\n改变pytest的默认规则，方式有三种：\n\n命令参数，例如pytest -v，-开头。\n在根目录创建一个pytest.ini配置文件，小写字母。\n环境变量（很有限），大写字母。\n\n\n获取配置值的方式：pytest -h。\n常见的命令参数:\n\n-v: 增加详细输出。\n-s: 在用例中正常使用输入输出*，默认情况下pytest会捕获输出。\n-x: 快速退出，一旦有用例失败就退出。\n\n\n-m: 用例筛选例如pytest -m web，只执行标记为web的用例。\n\n标记\n\n用例标记，装饰器：@pytest.mark.标记名，例如@pytest.mark.web。\n标记的作用：筛选用例、分组用例、添加元数据。\n用户自定义标，仅用作用例筛选，例如@pytest.mark.slow。使用步骤：\n\n注册，命令参数或配置文件。 [pytest]markers =  api: 接口测试  web: 慢速测试  login: 登录测试\n\n标记，装饰器。 import pytest@pytest.mark.slowdef test_slow_function():  assert True\n\n筛选，pytest -m marker。\n\n\n\n\n框架内置标记，可以增加特殊的执行效果，例如@pytest.mark.skip。\n\nskip: 无条件跳过用例。\nskipif: 条件跳过用例。\nxfail: 预期失败。\nparametrize: 参数化用例。\n数据驱动测试=参数化测试+数据文件\n含义是，根据数据文件的内容，动态决定用例的数量、内容。\nusefixtures: 使用fixture。\n\n\n\n数据驱动测试\n\n从数据文件中读取数据，以列表按顺序赋值给参数。\n用例的数量由数据数量决定。\n例子：@pytest.mark.parametrize(&quot;a, b, c&quot;, read_csv(&quot;data.csv&quot;))def test_ddt(self, a, b, c):    assert add(a, b) == c \n\n\n夹具fixture\n\n创建一个fixture。\n\n  @pytest.fixturedef f():  # 前置操作  yield # 执行用例  # 后置操作\n\n使用，以参数形式传递给用例。\n\n  def test_1(f):    pass\n\n使用，标记。\n\n  @pytest.mark.usefixtures(&quot;fgh&quot;)def test_2():  pass\n高级用法\n\n自动使用fixture。\n\n在配置文件中设置autouse = True。\n在用例中直接使用，不需要传递参数。\n\n@pytest.fixture(autouse=True)def f():    # 前置操作    yield    # 后置操作\n\n依赖使用。\n\n在一个fixture中使用另一个fixture。\n\n@pytest.fixturedef f1():    # 前置操作    yield    # 后置操作@pytest.fixturedef f2(f1):    # 使用f1的前置操作    yield    # 使用f1的后置操作\n\n返回内容。\n范围共享。\n\n","categories":["笔记","python"],"tags":["笔记","python","pytest","测试","测试框架"]},{"title":"《郑伯克段于鄢》筆記","url":"/2025/06/19/%E3%80%8A%E9%83%91%E4%BC%AF%E5%85%8B%E6%AE%B5%E4%BA%8E%E9%84%A2%E3%80%8B%E7%AC%94%E8%AE%B0/","content":"字、詞、表达記錄\n\n叔，生莊公及共叔段。古人命字常以伯（孟）、仲、叔、季表示長幼次序，但是會結合具體情況使用。在這裏，鄭莊公兄弟只有兩人，因此弟弟稱為“叔”。而“季”則用於兄弟多人的情況。\n亟，亟請於武公。讀做qì是，意屢次。也讀做jí，意急忙。\n都，大城。漢以後，“都”才指國都。補充： 京，大。先秦時，“京師”連用才指國都。\n若/奈/如 + 之/若 + 何，對他怎麼辦。語法上這是动词性凝固结构，是先秦特有的疑问短语，不可拆解。\n斃，倒下去。多行不義，必自斃。\n姑，暫且。本意是父親的母親、姐妹，或者丈夫的姐妹，她們往往展現出緩和、安撫、遷就、妥協的姿態，因此“姑”慢慢引申為一種處理事情的態度，這已經比較接近“暫且”的含義。\n暱，不義不暱。音nì，同“昵”，親近。這句話的意思是，段既然不義，就不能籠住民心。\n具，齊備、完整。具眼，意為眼力好，見識高；具瞻，意為眾人瞻仰。而具臣卻是指備位充數，不稱職的臣子。具臣可以理解為表面上完美的臣子，因為真正的“具臣”不可能存在，它對一個臣子的要求是方方面面，甚至是矛盾的。姑此說乃諷刺。而“具眼”、“具瞻”等是可以實現的。\n施，（潁考叔）愛其母，施及莊公。讀作yì，延伸，延續。\n\n文章細節\n\n\n\n（姜氏）請京，（莊公）使（共叔段）居之，（人們）謂之京城大（tài）叔。\n\n杜预《春秋左传注》中說：“大叔，言寵之逾制，非禮也。大音泰。”\n\n\n\n既而大叔命西鄙北鄙貳於己。\n\n貳，兩屬。這句話的意思是，不久之後，共叔段命令西部、北部邊邑的守臣效忠莊公的同時效忠自己。\n\n\n\n無生民心。\n\n這句話的意思是，不要是民眾產生二心。在古文語境裏，“民心”本就具有一心的預設，就像是個常識，這是對統治者一體的心。這個時候如果說生民心，那便在原本的心之外另一個心，也即二心。\n\n\n感悟\n說《春秋》微言大義，而《左傳》為其註解，可我讀了本篇後依然無法理解所謂“大義”。\n文章開頭就讓人眉頭緊皺——姜氏因為生莊公時難產，所以討厭莊公。這讓我想起了帶小孩的場景，小孩子頑皮摔了一跤，很多大人有意無意地會引導小孩子把摔跤的責任歸咎於地不是好地。姑常常看到大人抱著小孩，邊拍打各種事物，邊說：“壞xx，惹我家寶哭了”。這個法子似乎真有效。姜氏就是這麽個小孩子，可難產怪不得地，更怪不得自己，所以是莊公的過錯。很多現代人也會有類似的心理，\n再後來段與姜氏謀反被平定，莊公與之“隨而相見”，賦詩作樂，母子如初。態度轉變之快讓人難以理解。疼愛的小兒子被討厭的大兒子打敗了，她大兒子沒有深仇大恨；又或者，偏愛小兒子，意圖推翻大兒子，她也不覺得對大兒子有愧。這種時候，她沒有選擇硬剛到底，也沒有選擇真誠道歉。而是選擇把過去埋葬。這母親做得也太容易了。這就是歷史上的“普通人”，就像我們身邊常見的一個普通女生，沒有對自己人格的要求、反思，缺乏對他人的體諒、共情，而且不要臉。\n對本文主旨的主流理解是揭露莊公的偽裝與奸詐。我覺得莊公之所以被認為惡，是因為他發現了道德的漏洞，現在叫“站在道德的高地”。這場事件裏，莊公是被置於危機的，叛亂的、不公的是段和姜氏，正因如此莊公利用了他之惡，將自己塑造成受害者，但是實際上他掌握了一切。無疑，莊公是權謀的高手，但是他是否是惡？我認為不是。他的做法是為了解決問題的同時獲得好名聲，那為什麼不做這些虛偽的鋪墊就無法獲得好名聲呢？莊公甫一即位，姜氏和段就小動作不斷，這時下手，可能會被說多疑猜忌、心胸狹小云云。段日益膨脹時下手，罪證不足難以根除，若它日再起禍患，可能會被評價為優柔寡斷。以上是我的猜測，但是可以想到想要在所有人嘴裏都是好名聲是很難的事情，不僅得靠個人品德，還得看氣運，很多事情發生之前都無法準確預測。姜氏可以開城門做內應就說明了問題，姜氏絕不是省油的燈，她不是有德之人，但有一定權勢。莊公的處境也有一定的危險性。所以莊公選擇先隱忍，一方面可以一擊必殺，另一方面也可以麻痺對手降低自己的風險，同時也可以儘可能獲得好名聲。為了保全自己使用計謀，無可厚非。至於他有沒有為了好名聲偽裝自己，誰也不知道，況且是與不是也並非重要的事情。倘若莊公為了名聲選擇了更危險更不理智的方法，那才是真正的虛偽。\n","categories":["古代汉语","王力《古代汉语》笔记"],"tags":["古代汉语"]},{"title":"各类小工具（一）","url":"/2025/06/30/%E5%90%84%E7%B1%BB%E5%B0%8F%E5%B7%A5%E5%85%B7%EF%BC%88%E4%B8%80%EF%BC%89/","content":"查看图片\n\n\n\n名称\n安装\n用法\n简介\n\n\n\n\nviu\nbrew install viu\nviu img.jpg\n以字符色块的形式显示图片\n\n\nchafa\nbrew install chafa\nchafa img.jpg\n默认画面更加精细\n\n\n\n终端命令\n\n\n\n名称\n安装\n用法\n简介\n\n\n\n\ntldr\nbrew install tldrnpm install -g tldr\ntldr 命令\n查看命令用法，man的替代\n\n\n\n注：\n\ntldr切换语言: 可以使用tldr tldr查看语言相关命令，生成配置（有命令），修改完写入配置（给了查看配置位置的命令）里，还需要使用更新命令，最后可以查看语言列表。\n\npython实用工具\n\n\n\n名称\n安装\n用法\n简介\n\n\n\n\npipdeptree\npip install pipdeptree\npipdeptreepipdeptree -p 包名\n查看包依赖关系，可用来辅助清理不用的包\n\n\n\n编辑技巧\n可以在注释里添加TODO，插件Todo Tree可以自动识别，并形成方便查看跳转的树状视图。常用关键词如下：\n\n\n\n关键词\n用途说明\n\n\n\n\nTODO\n待办事项，尚未完成的功能或任务\n\n\nFIXME\n需要修复的问题或错误\n\n\nBUG\n明确标识存在的 bug\n\n\nHACK\n暂时性、非理想的实现方式\n\n\nNOTE\n重要说明或提醒\n\n\nOPTIMIZE\n可能需要优化的代码\n\n\nREFACTOR\n需要重构的代码段\n\n\n使用方法举例：// TODO: 实现用户权限校验\n\n\n\n\n","categories":["实践指南","小玩意"],"tags":["记录","工具用法","实践指南"]},{"title":"不想干活，趁着新鲜劲再写点东西","url":"/2025/06/06/%E4%B8%8D%E6%83%B3%E5%B9%B2%E6%B4%BB%EF%BC%8C%E8%B6%81%E7%9D%80%E6%96%B0%E9%B2%9C%E5%8A%B2%E5%86%8D%E5%86%99%E7%82%B9%E4%B8%9C%E8%A5%BF/","content":"不想干活，趁着新鲜劲再写点东西\n最近一直在做大模型语义缓存的项目，我总有种“不实”的感觉。这件事情最早两三年前就已经有人在做，但是目前市场上依然没看到有一个成熟的方案。我们给出的方案也依然是依葫芦画瓢，没有解决核心问题，或者说，我们目前搞不清楚什么是核心问题。不过我不想谈论烦心事，因为这种小事很难掩盖我拥有个人博客的喜悦。\n我想说一说开心的事情。前阵子打乒乓球认识了一个管院的男生，很符合我对管理学专业的刻板印象，说起话来一股子擅长pua的公司老板的气息。他总是试图将他的暴论灌输给我，我其实很需要这样的挑战。以往我的社交面很窄，这给我带来了很多的困扰，但当我的人生开始踏入新的阶段，我非常渴望改变。我与人的联系除了发生在实验室，也随着我的爱好，比如打乒乓球，逐渐扩充。在乒乓球以外的另一个场景，我面临着更加严峻的挑战，所以我非常乐意有练手的机会。他似乎也对隔三差五的争论很感兴趣，一来二去我们居然也成了不错的朋友。与我每天相对固定的生活轨迹不同，他经常参加各类社交活动，露营、桌游，有时也会叫上我。我意识到这就是我想象中通过少量的中继节见识到更多节点的交友方式，这让我转变对他的对抗态度——他也许是我研究生阶段的贵人。\n今天把成功让我的笔记本也可以写blog了，这种统一感还是很舒服的。\n从实验室回来吃饭，准备晚上去打球，电梯口遇到了过去的室友，他即将读博。一直以来我害怕碰到他们，人家出于礼貌的寒暄会让我很尴尬。但我觉得我应该更坦荡一些，比起别人我确实浪费了三年的时间。但是我不应该觉得羞愧，我的朋友们也不会因为这个而轻视我。更何况，我现在面对的是全新的人生，积极向上的生活本身就充满了力量，足以抵抗也许会存在的闲言碎语。\n开头这几篇blog杂乱宽泛，我不应该把blog当做草稿，而应当是成熟完整的文章，所以我以后尽可能给每一篇设计好一个固定的主题，做一些有深度的思考。\n","categories":["杂谈","日志"],"tags":["记录","杂谈","日志","随笔"]},{"title":"大模型学习笔记（一）——综述笔记","url":"/2025/08/12/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E7%BB%BC%E8%BF%B0%E7%AC%94%E8%AE%B0/","content":"综述《Large Language Models: A Survey》粗读\n摘要\n本文主要内容包括：\n\n阐述当下主流的三个大模型家族（GPT,LLaMa,PaLM)的特点、贡献和局限性。\n总览了制作、增强大模型的技术。\n介绍了用于大模型训练、微调、评估的数据集。\n介绍了大模型评估指标，并对比了各类大模型在一些代表性的benchmark上的表现。\n讨论了一些公开的挑战和未来的研究方向。\n\n图表\n模型、技术概览\n\n规模较小的模型无法拥有Emergent Abilities（涌现能力），它不是线性增长的，而是在模型的参数量达到某一个临界值后突然“获得”的。\n涌现能力包括上下文学习、指令跟随、多步推理。\n\n可以看到使用频率最高的训练数据库是Common Crawl、代码数据集（GitHub、Code datasets、SlimPajama 等）、学术/科学数据集（Arxiv、StackExchange、DocBank）。\n\n通过预训练得到一个学会通用语言表示的模型，然后通过微调来解决具体的任务。\n预训练的流程：\n\n以掩盖部分词的句子对的形式输入，让大模型预测掩盖的是什么，并且输出下一句预测。\nE是嵌入表示，是每个 token 的嵌入向量是三个部分相加的：Token Embedding（词嵌入）、Segment Embedding（句子 A/B 的区分向量）、Position Embedding（位置编码）。\nT是上下文表示（BERT真正“理解”后的词表示，可用于下游任务），是经过多层Transformer编码之后的输出向量，借由双向注意力机制整合了句子里其它所有词的语义信息。\n重点是理解掩盖词元(Masked Language Model - MLM)这种方式的意义。我们无法直接告诉模型一句话是什么意思，所以设计这样的训练方式，模型要去预测被掩盖的词，它就一定需要理解上下文。\n除了掩盖词元，在ELECTRA里引入了替换词元(Replaced Token Detection - RTD)，它替换了部分词，让模型去判断每一个词是原装的还是被替换的。\n\n[CLS] 和 [SEP] 这两个简写来自 classification 和 separator 的缩写：\n\n[CLS] 表示“分类专用标记”，在 BERT 中放在输入序列开头，用它的输出向量做句子级任务（分类、回归等）的特征表示。\n[SEP] 表示“分隔符标记”，用于分隔两个句子或标记序列的结束位置。\n\n微调的流程：\n复杂、暂略。\n\n\nXLM的MLM与BERT的MLM的区别是，它不是成对句子输入，而是流式的输入，目标都是预测被掩盖的词。\nXLM的TLM部分需要再不同语言的表征间对齐(alignment)。\n\n\n\nUniLM的特点是使用一种模型结构，支持了三种模式：双向语言模型(Bidirectional LM)、单向语言模型(Left-to-right LM)、序列到序列语言模型(Seq-Seq LM)。\n实现方式是使用注意力遮罩，限制计算一个词的表示时，它能看到哪些其它的词，方式如图所示。\n\n\n\n左边描述了GPT的宏观结构，输入经过文本编码和位置编码，进入12层的Transformer编码器，最后得到文本预测和任务分类的结果。\n右边是四种任务的微调方法：文本分类(Classification)、文本蕴含(Entailment)、文本相似度(Similarity)和多项选择(Multiple Choice)。\n这里通过构造不同的输入格式、Transformer模块的数量和组织形式，来构造不同的任务。\n\n\n\n误区阐述： 我认为这幅图最有价值的地方并非是说明了模型越大从上下文中学习的能力就越强，这一点可能是正确的，这也是所谓涌现的一种表现。\n提示词是无关因素： 通过对比实线与虚线，可以发现三色的一个共同点，在示例足够多的时候，有无提示词变成了一个无关因素，示例非常有限时，提示词才会有作用。\n提示词和示例是交叉并行的： 我想这很好理解，少量示例描述任务范围太大，示例充分则可以清晰地定义任务的边界。提示词和示例是两条并行的路，终点都是为了向大模型描述任务。\n提示词和示例的深层内涵： 大语言模型理解文字任务描述的过程是将文字抽象化成为某种任务表示，理解示例也是如此，所以关键问题是这种转化的质量和速度。当前对 ICL(In-context Learning) 的几种理论对此有不同的解释：\n\n贝叶斯推断理论（Bayesian Inference Hypothesis）：模型在上下文中形成对“潜在任务”的后验分布，ICL 则是在给定样本条件下的分布更新。\n线性/核回归视角：Transformer 在上下文内执行一种近似回归/检索加权。\n元学习理论（Meta-Learning Hypothesis）：模型学会了读示例→拟合小问题的“内在优化器”，ICL 只是把这个能力激活出来。\n模型记忆检索理论（Retrieval / Pattern Matching Hypothesis）：模型在预训练阶段记住了大量“类似任务的模式”，ICL 时只是在检索和组合它学过的模式。\n模拟微调理论（Implicit Fine-Tuning Hypothesis）：ICL 的本质是隐式的梯度下降，模型在推理时，会用前面示例去更新内部的“激活状态”，等价于在临时微调参数（虽然物理参数没变）。\n\n\n困难原因分析： LLM之所以无法从可能在人类看来清晰的规律或者描述中准确学习到精准的任务表示，我认为有以下几种原因：\n\n抽象的任务表示的可能性太多，模型难以精准定位到目标任务，具体来说有以下几类原因：\n\n先验错配：预训练的下一个词目标未必鼓励精确执行算法式规则，模型会选择更便宜的启发式。\n分布与格式偏差：示例格式、顺序、位置对注意力有强影响；噪声或冲突示例会让后验发散。\n上下文容量与干扰：长上下文中远端示例衰减，易被近端干扰覆盖（recency bias）。\n解码策略影响：温度、惩罚项会放大/缩小启发式偏好，导致“看起来会”但输出不稳。\n指令对齐程度：没有做过指令调优/对齐的基座模型，指令可读但不一定“优先服从”。\n\n\n模型可以表达的任务表示的种类有限，没有覆盖目标任务。\n\n\n解决路线： 我认为可以从纯自然科学的角度出发，研究大模型如何表示任务，再根据成熟的理论定制化设计模型的任务表示能力。\n\n自上而下（工程对齐）：指令微调、合成数据覆盖、格式鲁棒训练、思维链/检验器、工具调用与规划模块化，把“任务表示”外显化并可控。\n自下而上（机制研究）：可解释性分析注意力回路、软提示/前缀向量作为“任务嵌入”、在合成分布上验证 ICL 的内在算法与失效模式。\n相关领域：大模型可解释性（Interpretability）和神经符号（Neuro-Symbolic AI）\n\n\n\n\n\n\n监督微调（SFT）：使用人工标注、设计的数据进行一次粗对齐。\n公式：\nmin⁡θ  LSFT(θ)=−E(x,y)∼DSFT[log⁡πθ(y∣x)]\\min_{\\theta} \\; L_{\\text{SFT}}(\\theta) \n= - \\mathbb{E}_{(x, y) \\sim D_{\\text{SFT}}} \\left[ \\log \\pi_\\theta(y \\mid x) \\right]\nθmin​LSFT​(θ)=−E(x,y)∼DSFT​​[logπθ​(y∣x)]\n参数说明：\n\nπθ(y∣x)\\pi_\\theta(y \\mid x)πθ​(y∣x)：策略模型的条件概率\nDSFTD_{\\text{SFT}}DSFT​：人工标注数据集\nθ\\thetaθ：策略模型参数\n\n\n\n奖励模型（RM）：对于同一个prompt让模型生成多条回答，人工排序，用以训练一个模型输出的打分器。\nmin⁡ϕ  LRM(ϕ)=−E(x,y优,y劣)∼DRM[log⁡σ(rϕ(x,y优)−rϕ(x,y劣))]\\min_{\\phi} \\; L_{\\text{RM}}(\\phi) \n= - \\mathbb{E}_{(x, y_{\\text{优}}, y_{\\text{劣}}) \\sim D_{\\text{RM}}} \n\\left[ \\log \\sigma \\left( r_\\phi(x, y_{\\text{优}}) - r_\\phi(x, y_{\\text{劣}}) \\right) \\right]\nϕmin​LRM​(ϕ)=−E(x,y优​,y劣​)∼DRM​​[logσ(rϕ​(x,y优​)−rϕ​(x,y劣​))]\n参数说明：\n\nrϕ(x,y)r_\\phi(x, y)rϕ​(x,y)：奖励模型的实数分输出\ny优,y劣y_{\\text{优}}, y_{\\text{劣}}y优​,y劣​：人类标注的优劣答案\nσ(z)=11+e−z\\sigma(z) = \\frac{1}{1 + e^{-z}}σ(z)=1+e−z1​：Sigmoid 函数\nDRMD_{\\text{RM}}DRM​：人类偏好排序数据集\nϕ\\phiϕ：奖励模型参数\n\n\n\n强化学习（RL）：使用PPO算法，根据打分器的结果调整模型参数，迭代循环，直到足够符合人类偏好。\n公式：\nmax⁡θ  Ex∼D,  y∼πθ(⋅∣x)[rϕ(x,y)−β  KL(πθ(⋅∣x) ∥ πref(⋅∣x))]\\max_{\\theta} \\; \\mathbb{E}_{x \\sim D, \\; y \\sim \\pi_\\theta(\\cdot \\mid x)}\n\\left[ r_\\phi(x, y) - \\beta \\; \\mathrm{KL}\\big(\\pi_\\theta(\\cdot \\mid x) \\,\\|\\, \\pi_{\\text{ref}}(\\cdot \\mid x)\\big) \\right]\nθmax​Ex∼D,y∼πθ​(⋅∣x)​[rϕ​(x,y)−βKL(πθ​(⋅∣x)∥πref​(⋅∣x))]\n参数说明：\n\nπθ\\pi_\\thetaπθ​：当前策略模型\nπref\\pi_{\\text{ref}}πref​：参考策略（通常是 SFT 模型或早期快照）\nrϕ(x,y)r_\\phi(x, y)rϕ​(x,y)：奖励模型的分数\nβ\\betaβ：KL 惩罚系数\nKL(p∥q)\\mathrm{KL}(p \\| q)KL(p∥q)：KL 散度，衡量分布差异\n\n\n\n直觉上这个过程不精准，因为RM不是精准的，它的误差在RL那会被放大。\n\n这个评估的流程是：\n\n准备一批多样化的测试问题。\n让每个模型输出回答。\n让GPT-4作为裁判，对每个模型的回答进行评估，直接输出一个分数，或者做配对比较，看哪个更好，赢得一分，输扣一分。\n\n\n\nPretrain–finetune(预训练 + 微调)：在某个具体任务(task A)上进行微调。最终模型专门用于该任务。\nPrompting(提示学习)：不做进一步微调；在预测时用提示(prompts)或少量样例(few-shot learning)提高在某个任务(task A)上的表现。\nInstruction Tuning(指令微调)：用多种不同类型的任务数据，用自然语言指令来微调模型，从而让模型学会“听从指令”这个元能力。\n\n\n\n把输入序列分块（chunking），每个chunk作为一个处理单元。\n从外部数据库检索相关片段(retrieval)，找到“邻居”序列作为参考。\n通过交叉注意力(chunked cross-attention, CCA)融合检索到的邻居信息。\n继续像普通Transformer块一样处理，生成预测。\n\n问题：\n\nRetrieval数据库如何构建？\nCCA过程多大程度上有效？为何有效？\nCCA的子过程CA做了什么事情？\n\n\n上半部分是传统的Transformer模型，下半部分是MoE层。\n通过一个Gating(门控)模块选择决定激活哪些专家(FFN)。\n\n人类的反馈有两种形式：\n\n偏好响应，模型生成多种答案，人类评估员选择他们认为最好的。\n对抗性探测，人类评估员扮演敌手(adversary)用各种方式诱导模型违反规则，以此找出模型的弱电和漏洞。\n\n\n\nS-denoiser (序贯去噪 / Sequential Denoising): 这本质上就是GPT系列的训练方式，即“下一个词预测”。给模型一段前文（prefix），让它续写后面的内容。这个任务特别擅长训练模型的生成能力和上下文学习 (In-context Learning) 能力。\nR-denoiser (常规去噪 / Regular Denoising): 这类似于T5模型的训练方式。它会随机遮盖文本中一些较短的片段，让模型去填空。这个任务对于训练模型的语言理解能力非常有效。\nX-denoiser (极限去噪 / eXtreme Denoising): 这是R-denoiser的“困难模式”。它会遮盖掉非常长的文本片段，或者以非常高的比例破坏原文。这迫使模型必须依赖更长距离的上下文信息和世界知识才能恢复原文，从而极大地锻炼了模型的长程推理能力和知识储备。\n\n\n\n左：整体结构，LN是Layer Normalization。\n中：解码器内部。\n右：多头注意力，核心创新是ALIBI Mask (Attention with Linear Biases)。\n解释：\n\nALIBI是一种相对位置偏置，根据位置信息为注意力分数添加偏置的方法，抛弃了原本Transformer模型中的位置编码。\n右上角为-inf的原因是模型不应该看到未来信息，杜绝信息穿越。\nkhead是一个与注意力头相关的常数斜率，每个注意力头都有自己专属的khead值，这意味着不同的注意力头可以有不同的距离敏感度。\n\n\n\n构建大模型\n\n大型语言模型（LLMs）从数据到最终应用的构建流程：干净数据 → 分词编码 → 架构设计 → 预训练 → 微调 → 对齐 → 文本生成 → 优化压缩。。\n\n\n\n阶段\n目标\n常见方法\n示例 / 说明\n\n\n\n\n数据清理\n保证数据干净\n过滤、去重\n移除噪音，异常值处理，语言比例平衡，文本预处理\n\n\n分词\n转换成 token 序列\nBPE、WordPiece、SentencePiece\nLLM 不直接“理解文字”，而是把字符串拆解为token序列，再转换成向量输入模型。\n\n\n位置编码\n表达顺序信息\n绝对PE、相对PE、RoPE、偏置\n避免退化成“词袋模型”\n\n\n模型架构\n设计模型结构\nEncoder-Only、Decoder-Only、Encoder-Decoder\nBERT → 理解；GPT → 生成；T5/BART → 翻译/摘要\n\n\n预训练\n大规模自学\nMLM、CLM、NSP、MoE\n最耗算力阶段，构建通用语义能力\n\n\n微调 &amp; 指令调优\n贴合实际任务\n监督式微调、领域微调、指令跟随\nChatGPT 相比GPT的关键步骤\n\n\n对齐\n符合人类价值 &amp; 安全\nSL、RLHF、DPO、KTO\n控制输出，防止有害内容\n\n\n解码策略\n文本生成方式\nGreedy、Beam、Top-k、Top-p\n影响创造性和连贯性\n\n\n高效训练与压缩\n降低成本 &amp; 延迟\nZeRO、RWKV、LoRA、蒸馏、量化\n让LLM真正落地应用\n\n\n\n\n\n输入与嵌入。输入包括，输入编码+位置编码，因为Transformer 的自注意力机制一次性看整个序列，不像 RNN 或 LSTM 那样按顺序处理，所以模型本身不知道词在序列中的位置，所以需要添加位置编码。\n编码器，左侧。编码器由N层堆叠（论文里一般是6层），每一层包含Multi-Head Attention (多头注意力机制)、Add &amp; Norm (残差连接 + 层归一化)、Feed Forward 全连接网络。编码器把输入序列压缩成一系列“上下文向量”，富含语义。\n解码器。右侧。解码器也有 N 层堆叠，多了一个Masked Multi-Head Attention（遮掩多头注意力）。同时它的多头注意力也接收编码器的输出，这使得翻译任务成为可能。\n输出层 (Linear + Softmax)。Linear：把解码器的输出向量投射到词汇表大小的维度。Softmax：转化为概率分布 → 预测下一个词最可能是哪一个。\n\n\n\nDocument Preparation（文档准备阶段）\n\nURL Filtering（网址过滤）\nText Extraction（文本提取）\nLanguage Identification（语言识别）\n\n\nFiltering（内容过滤阶段）\n\nRepetition Removal（重复内容去除）\nDocument-wise Filtering（文档级过滤）\nLine-wise Corrections（逐行清理）\n\n\nDeduplication（去重阶段）\n\nFuzzy Deduplication（模糊去重）\nExact Deduplication（精确去重）\n\n\n\n\n\nAbsolute Positional Embeddings（绝对位置编码）：每个输入token的词向量w_i会加上一个位置向量p_i，表示该词在序列中的绝对位置。比较简单。\nRelative Positional Embeddings（相对位置编码）：关注的是两个token之间的相对距离，而不是绝对位置。更符合自然语言的特点，词序关系（例如“X在Y前”）比绝对位置更重要。\nRotary Positional Embedding (RoPE, 旋转位置编码)：把位置信息编码成一个旋转矩阵，使得query/key向量在位置变化时经历一个复数域上的旋转。本质是把位置信息通过旋转矩阵编码到Q/K上。这是目前最主流的位置编码方式。\nRelative Positional Bias（相对位置偏置）：在 attention 分数矩阵中额外加入一个依赖于相对位置的偏置项。如ALIBI。\n\n相对位置编码（特别是RoPE和ALiBi）通常比绝对位置编码在处理长序列时表现更好。因为它们关注的是局部相对关系，更容易泛化到比训练时更长的文本。\n\n左图是整体结构，右图是详细内容。\n右图展示的是词元级别的稀疏专家模型，每个token在注意力计算后，带着整句的信息进入Switching FFN层，保证了统一性。并且通过残差连接（兜了一圈的实线）确保了信息主干的完整性。\n图中虚线表示的是概率，最终结果是FFN数超出乘以概率。\n\nRLHF除了复杂、不稳定、资源消耗大之外，还有一个问题是“奖励模型漂移”，即强化学习过程可能会找到奖励模型的漏洞，生成一些能得高分但实际上质量很差的文本（奖励骇客, Reward Hacking）。\nDPO删除了奖励模型，直接优化语言模型，更简单，且在很多常见任务上性能与 RLHF 相当，有时甚至略好，但在非常复杂、长序列或特定领域任务上，RLHF 有时仍能略优。\n\nKTO只需要二元反馈（好/坏），而不需要奖励模型，也不需要人工比较判断。\n优点在于：\n\n这种数据在现实世界中随处可见，收集容易、成本极低。\n符合人类心理学的“损失厌恶”。\n在某些基准测试上与DPO相媲美甚至更优。\n\n注：本图πref向下也有一个箭头，这并不代表RM从πref训练，而是πref的输出结果以及它们的排序（从左来）是RM训练的数据来源。\n\n左边蓝色方框W是冻结的原始参数，右边通过A降维再到B升维，最后与原始参数相加。\nA的形状是d*r，将x从高维d映射到远小的r，B的形状是r*d，这种方式使得只需要修改2*r*d个参数，远远小于d2。\n\n\n数据输入给教师模型。\nDistill（蒸馏）：教师模型生成软标签（soft label），软标签是概率分布，不是硬标签那种绝对的0或1。这种方式包含了丰富的信息，可以让模型学习到类别之间细微的差别。\nTransfer（传递）：学生模型接收数据和软标签，通过对比学习的方式，学习到与教师模型相同的知识。\n\n\n上图简单明了，不作解释。\n\n工作流程总结：\n\n用户向Policy模块提问。\nPolicy模块查询Working Memory，分析当前情况，决定下一步行动（比如：搜索）。\nAction Executor执行搜索指令，从External Knowledge中获取信息，并整合成一个Prompt。\nPrompt被发送给LLM，LLM生成一段文本。\n生成的文本和检索到的知识被存入Working Memory。\nPolicy模块判断现在是否可以回答用户，如果可以，就将LLM生成的最终答案发送给用户。\nUtility模块根据用户反馈和任务完成情况，生成一个效用分数。\n这个分数被用来更新Policy模块，让智能体在下一次对话中变得更聪明。\n\n\n\nBasic Datasets (基础数据集 - 红色部分)\nEmergent Datasets (涌现能力数据集 - 绿色部分)\nAugmented Datasets (增强/工具使用数据集 - 蓝色部分)\n\n注：预训练阶段是“孕育”和“产生”了涌现能力的【潜力】。微调阶段是“解锁”、“引导”和“强化”了这个【潜力】，使其变得可用和可靠。\n\n上图展示了各类Benchmark，和它们的评估指标。超链接需要打开原论文查看。\nEvaluation Metric (评估指标):\n\nPASS@k: 用于代码生成任务，表示模型生成 k 个答案中至少有一个能通过单元测试的概率。\nAccuracy (准确率): 用于分类或选择题任务。\nF1-score, EM (Exact Match, 精确匹配): 常用于问答任务，衡量预测答案与标准答案的重合度。\nROUGE: 常用于文本摘要任务，衡量生成摘要与参考摘要的重合度。\nBLEU: 常用于机器翻译，衡量生成文本与参考文本的相似度。\n\nBenchmark分类：\n\n代码生成能力 (Code Generation)\n\n代表基准: HumanEval, MBPP, APPS, CoNaLa, CodeParrot\n评测内容: 测试模型根据自然语言描述生成可执行、正确的代码（主要是 Python）的能力。\n\n\n推理与问答能力 (Reasoning &amp; Question Answering)\n\n代表基准:\n\n常识推理: HellaSwag, CommonsenseQA, PIQA, SIQA\n多项选择/阅读理解: AI2 Reasoning Challenge (ARC), BoolQ, RACE, SQuAD, DROP, Natural Questions, TriviaQA, OpenBookQA\n多跳推理: HotpotQA (需要结合多个文档信息才能回答)\n\n\n评测内容: 评测模型理解文本、进行逻辑推理并准确回答问题的能力。\n\n\n文本摘要能力 (Summarization)\n\n代表基准: CNN/Daily Mail, XSUM, SAMSum, WikiSum, DialogSum\n评测内容: 测试模型将长篇文章或对话精炼成简短、准确摘要的能力。\n\n\n数学推理能力 (Mathematical Reasoning)\n\n代表基准: GSM8K, MATH\n评测内容: 专门测试模型解决数学应用题的能力，需要多步推理和计算。\n\n\n综合能力与多任务评估 (General &amp; Multi-task Evaluation)\n\n代表基准: MMLU (大规模多任务语言理解), BIG-bench\n评测内容: 这类基准涵盖了从基础科学到人文学科的数十个不同主题，全面评估模型的知识广度和解决多样化问题的能力。\n\n\n工具/API 调用能力 (Tool/API Usage)\n\n代表基准: ToolTalk, MetaTool, GPT4Tools, API-Bank\n评测内容: 这是较新的评测方向，测试 LLM 是否能理解并正确调用外部工具（如计算器、搜索引擎、API）来完成复杂任务。评估指标也更复杂，如“成功率”、“API幻觉错误”等。\n\n\n真实性与指令遵循 (Truthfulness &amp; Instruction Following)\n\n代表基准: TruthfulQA (评估模型回答是否真实，避免生成误导信息), Natural Instructions (评估模型遵循复杂指令的能力), Alpaca-CoT (评估模型的思维链推理能力)。\n\n\n\n\n\nFoundation model (基础模型)：预训练的语言模型（Pretrained language model）。这是最原始的形态，仅通过大量文本数据进行自监督学习。\nInstruction model (指令模型)：预训练 + 指令微调的语言模型（Pretrained and instruction fine-tuned language model）。在基础模型上，使用包含“指令-输出”对的数据进行微调，使其能更好地遵循用户指令。\nChat model (聊天模型)：预训练 + 指令微调 + 对话微调的语言模型（Pretrained, instruction fine-tuned, and chat fine-tuned language model）。在指令模型的基础上，进一步使用人类与 AI 的对话数据进行微调，使其具备更自然的对话能力。\n\n","categories":["笔记","LLM"],"tags":["LLM","大模型","Transformer","Attention","Tokenizer","Embedding","综述"]},{"title":"晚安，世界","url":"/2025/06/06/%E6%99%9A%E5%AE%89%EF%BC%8C%E4%B8%96%E7%95%8C/","content":"晚安，世界\n现在是0:30，我本已下决心不再熬夜，但在我又一次听到个人域名的想法，我决定行动起来。从大约十点，一直到现在，我申请了lixiang.us.kg这个域名，创建了cloudflare上的图床，用hexo创建并上传第一篇博客到github。一切都打通以后，我跟着教程安装了第一个个性化主题——Fluid。非常感谢B站up主陶渊xiao明，他的三个视频完美解决了我的大多数问题。\n个人博客给我的感受与本地的日记完全不同，它提供了一丝可能性，就像是黑暗的房子裂开了一道缝隙，传进来的光或许很小，但它改变了一切。在本地的笔记里，只有一个角色。回想起来，我已经很久没有好好写过日记。与自己交流的方式从与幻想的日记精灵对话变成了更加现实、冷峻地与自己对话，偶尔的散步成为了全部审视自身的时间。这个岁数我已很难沉浸到过去那种深度的幻想世界里，我无法对着本子或者屏幕虚构出一个听我诉说的朋友，我并不是觉得可笑，而是真的无法代入。这感觉就像是，我18年玩到第一部3A（刺客信条：起源）时，兴奋到梦里都是那个世界，但是面对去年的刺客信条：幻景，我已经无法忽视它的各种缺点。对，就是这样，如果我要在面前虚构一个朋友，我会不由自主地想到这件事情的不合理性（疑点）。就比如我会觉得虚构的朋友是孩童特有的心理现象，我感觉这也许是精神分析学的研究范畴。\n不过不用去管那些事情，无关紧要。现在我的对面是无比真实的世界，而且我们的连接是最浪漫的方式之一——有限、偶然。这又让我充满了动力。\n在我行动之前我对个人博客很怀疑，我分析不出它与本地日志有什么本质区别。这种怀疑在我准备关机回宿舍的一瞬间被彻底打消，看到Fluid这个主题氛围，我决定让我的博客以一个有仪式感的方式出现。《晚安，世界》这个念头蹦出来的时候，我感受到了那种随机却精准的推理方式——这个题目本只是为了说明夜深了，但却在与世界的第一次连接到意义上十分合适。\n晚安，世界，明天见。\n","categories":["杂谈","日志"],"tags":["记录","杂谈","日志","随笔"]},{"title":"大模型学习笔记（二）—-其它知识点总结","url":"/2025/08/16/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E5%85%B6%E5%AE%83%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","content":"如何让模型学习、理解自然语言和世界知识\n任务设计\n\n去噪自监督学习(Denoising Auto-Encoding)：破坏原文，让模型补充，BERT的MLM(Masked Language Modeling)就是这种任务。\n示例:\n原文: The chef cooked the meal.\n破坏后: The chef [mask] the meal.\n主模型的任务: 预测被 [mask] 替换的词是 cooked。\n自回归语言建模 (Autoregressive Language Modeling)：让模型从左到右逐个预测下一个词。\n示例:\n输入: 今天天气真不错，我们一起去\n模型的目标: 预测出下一个词是 公园、散步 或其他合理的词。\n学习到的能力: 这种方法极大地锻炼了模型的生成能力、流畅性和上下文关联能力。因为它必须根据已经出现的所有前文来推断最合理地延续，所以它对语境的理解非常深刻，这也就是为什么GPT系列擅长对话、写作和上下文学习(In-context Learning)。\n对比学习 (Contrastive Learning)：要求模型学会判断“相似”与“不相似”，将向量空间中向量的相似性对齐到自然语言的相似性。\n示例:\n正样本对: 今天天气真好, 今天是个大晴天 -&gt; 模型需要让这两个句子的向量表示尽可能接近。\n负样本对: 今天天气真好, 我的手机没电了 -&gt; 模型需要让这两个句子的向量表示尽可能疏远。\n学习到的能力: 这种方法特别擅长学习句子的整体语义表示。训练出的模型在语义搜索、文本匹配、文本聚类等任务上效果极佳，因为它能生成高质量的“句向量”。\n下一句预测 (NSP) / 句子顺序预测 (SOP)：给模型两个句子，让它判断这两个句子在原文中是否是连续的（NSP），或者判断它们的顺序是否正确（SOP）。\n示例 (NSP):\n输入: A: 我喜欢看电影。 B: 尤其是科幻片。 -&gt; 模型应判断 B 是 A 的下一句。\n输入: A: 我喜欢看电影。 B: 香蕉是一种水果。 -&gt; 模型应判断 B 不是 A 的下一句。\n学习到的能力: 这种方法让模型学习篇章结构、逻辑连贯性和话题流转，提升了对段落级别语义的理解。\n替换词元检测 (Replaced Token Detection - RTD)：不用 [MASK] 标签去遮盖词，而是用一个小的“生成器”模型生成一个看起来合理但却是错误的词来替换原文的词。然后让主模型（“判别器”）去判断每个词是原文中的真词还是被替换掉的假词。\n示例:\n原文: The chef cooked the meal.\n生成器替换后: The chef ate the meal.\n主模型的任务: 逐词判断，并指出 ate 是一个被替换的词。\n学习到的能力: 因为模型需要对每个词都进行判断，而不是只预测少数几个被遮盖的词，所以训练效率（样本利用率）大大提高。它能让模型学会辨别非常细微的语义和搭配差异。\n\n\n\n\n方法\n核心思路\n示例\n学习到的能力\n\n\n\n\n去噪自监督学习\n破坏原文，让模型补充\nThe chef [mask] the meal. → 预测 cooked\n学习词级语义补全，理解局部上下文\n\n\n自回归语言建模\n从左到右逐词预测下一个词\n今天天气真不错，我们一起去 → 预测 公园/散步\n提升生成能力、流畅性、上下文理解，擅长写作和对话\n\n\n对比学习\n判断相似与不相似\n正样本: 今天天气真好, 今天是个大晴天负样本: 今天天气真好, 我的手机没电了\n学习句子整体语义表示，适合语义搜索、文本匹配、聚类\n\n\n下一句/句子顺序预测\n判断句子是否连续或顺序是否正确\nA: 我喜欢看电影。 B: 尤其是科幻片。 → 连续A: 我喜欢看电影。 B: 香蕉是一种水果。 → 不连续\n理解篇章结构、逻辑连贯性和话题流转，提升段落语义理解\n\n\n替换词元检测\n用生成器替换部分词，让主模型判别\nThe chef ate the meal. → 判别 ate 是否被替换\n提升训练效率和语义辨别能力，理解细微语义和搭配差异\n\n\n\n超长输入文本的处理方式\n\n高效注意力机制 (Efficient Attention)\n这是解决**“算法瓶颈”**问题的关键。\n\n传统方式：标准的自注意力机制，要求文本中每个词都要和其他所有词进行比较，计算量与文本长度的平方 (O(N2)O(N^2)O(N2)) 成正比，处理长文本时会发生计算爆炸。\n高效方式：采用多种优化的注意力变体，打破 O(N2)O(N^2)O(N2) 的魔咒。核心思想是“不必让每个词都看遍所有词”。\n\n稀疏注意力 (Sparse Attention)：只计算最重要的词之间的关联。\n滑动窗口 (Sliding Window)：只关注每个词邻近的上下文。\n线性化 (Linearization)：通过数学近似，将计算复杂度降至与文本长度成正比 (O(N)O(N)O(N))。\n\n\n效果：让模型能在大规模文本中，以极高的效率建立起关键信息之间的长距离联系。\n\n\n外部系统架构的优化：现实系统会结合检索增强（RAG / Retrieval-Augmented Generation）。\n\n大模型的可解释性\nMechanistic Interpretability（机械可解释性）\n\n传统的可解释性 (Traditional Interpretability)：我们通过给它输入各种问题（prompt），然后观察它的输出（response）来猜测它的功能。\nMechanistic Interpretability（机械可解释性）：我们不应再把大模型看作一个无法理解的“黑箱”，而是要像拆解一台精密机器或解剖一个大脑一样，去反向工程（reverse-engineer）其内部的每一个组件和连接，精确地找出模型为了完成特定任务而自发学习到的“算法”或“神经回路”。\n研究人员已经取得了一些惊人的发现，例如：\n\n间接对象识别回路 (Indirect Object Identification Circuit)：\n\n在一个经典的研究中，研究者们找到了一个能精确解释模型如何完成以下任务的回路。\n句子：“当John和Mary走到商店时，John把一本书递给了__”\n模型能准确预测下一个词是“Mary”。MI研究者们通过追踪，发现了一个由几个特定注意力头组成的“电路”。这个电路的功能是：\n\n找到句子中所有的人名（“John”, “Mary”）。\n识别出最后一个动词的主语（“John”）。\n抑制（忽略）这个主语。\n将注意力集中在剩下的人名（“Mary”）上，从而输出正确答案。\n\n\n他们不仅发现了这个回路，还能通过人为“干预”（比如禁用其中一个注意力头）来精确地破坏这个功能，从而证明了他们的发现。\n\n\n事实关联与检索：\n\n模型如何“记住”埃菲尔铁塔在巴黎？MI试图找到存储“埃菲尔铁塔”概念的神经元，以及存储“巴黎”概念的神经元，并找出它们之间是如何通过特定的连接来表示“位于”这个关系的。\n\n\n更复杂的功能：\n\n研究人员正在尝试寻找更高级的回路，比如模型是如何进行逻辑推理、识别代码中的bug，甚至是模型可能存在的欺骗行为（Deception）的回路。\n\n\n\n\n\n数据存储与查询\n知识图谱\n它的最基本组成单位是三元组（Triple），即：（实体, 关系, 实体） 或者 （实体, 属性, 属性值）。目前常用大模型构建。\n","categories":["笔记","LLM"],"tags":["LLM","大模型","Transformer","Attention","Tokenizer","Embedding","LM","知识点， 总结"]},{"title":"远程连接win11主机","url":"/2025/06/09/%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5win11%E4%B8%BB%E6%9C%BA/","content":"远程连接win11主机\nssh（仅命令行）\n坑\n\n\n服务端防火墙要配置入站规则，开放22端口。\n\n\n客户端的公钥应该放在哪。\nChatGPT o3:\n\n管理员账户必须把公钥写入 C:\\ProgramData\\ssh\\administrators_authorized_keys​1。\n非管理员账户用 %USERPROFILE%\\.ssh\\authorized_keys​2。\n\n事实证明这一点不准确，FixedIdiot上的weimo账户不被认为是管理员账户，但是放在2没有效果，放在1却可以。我估计是因为判断标准是用户组，weimo在Administrators用户组里。\n\n\nRDP（微软远程连接，图形化界面）\n步骤\n\n\nWin11 服务器端\n“设置 → 系统 → 远程桌面 → 打开”，记下计算机名并确认用户在“远程桌面用户”名单内。\n\n\nWin10 客户端\n运行 mstsc​ → 输入服务器名/IP:PORT。\n\n\nTips\n\n要想校园网可以访问实验室网络（校园网的内网）内的主机，则需要配置一下端口映射3389、TCP协议。\n与其他远程桌面、多端协同的工具可能会产生冲突，例如同时Mouse without Boarders会导致鼠标消失。\n\n\n\n","categories":["实践指南","小玩意"],"tags":["记录","工具用法","实践指南"]},{"title":"配置一个舒服的wsl开发环境","url":"/2025/06/26/%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E8%88%92%E6%9C%8D%E7%9A%84wsl%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","content":"🦦配置一个舒服的wsl开发环境\nBUG: “wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。”\n\n\n打开或者创建%USERPROFILE%.wslconfig，添加\n [experimental]autoMemoryReclaim=gradual  # gradual  | dropcache | disablednetworkingMode=mirroreddnsTunneling=truefirewall=trueautoProxy=true\n\n\n关机wsl --shutdown Debian，重启wsl -d Debian。\n\n\n安装brew包管理器\n\n安装依赖项 sudo apt-get install build-essential procps curl file git。\n安装Homebrew /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;。\n配置环境变量和软链接 echo 'eval &quot;$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)&quot;' &gt;&gt; $HOME/.bash_profile，eval &quot;$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)&quot;。\n验证安装成功 brew doctor。\n用法：\n\nbrew install &lt;package_name&gt;\nbrew remove &lt;package_name&gt;\nbrew list\n删除不需要的依赖 brew autoremove\n\n\n删除Homebrew /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/uninstall.sh)&quot;\n\n安装、配置nushell\n\n安装nushell brew install nushell\n修改nushell为默认shell\n\n添加nu到shell列表里，有几种方式，行为可能因情况不确定，写在这作参考：\n\nbrew安装nu的默认位置是/home/linuxbrew/.linuxbrew/bin/nu，故可以echo &quot;/home/linuxbrew/.linuxbrew/bin/nu&quot; | sudo tee -a /etc/shells。\n在bash里执行which nu | sudo tee -a /etc/shells。\n\n\n修改当前用户的默认shell，这也有几种不确定的方式：\n\nchsh -s $(which nu)，或使用默认位置。\n直接修改/etc/passwd，将对应用户原本的.../bash改为nu的位置，root用户可能也需要修改。\n\n\n重启wsl，exit若无效，可以用wsl --shutdown Debian。\n\n\n一点小配置 # set default editor$env.config.buffer_editor = &quot;nvim&quot;# cancle default message when boot$env.config.show_banner = false\n\n注： 切换到nushell后环境变量都没了，brew、nushell 等都需要重新加入环境变量。\n\n安装、配置neovim\n\n安装neovim：brew install neovim\n安装Lazyman。\n\nLazyman的各种问题\n\nneovim版本需要高于0.9。\n使用lazyman（可能需要手动加入环境变量）命令打开交互式配置界面。\n菜单后面几个安装依赖的都得先装一下，之后再去安装配置。\n配置到nvim上需要写入环境变量，以nushell为例$env.NVIM_APPNAME = 'nvim-Python'。\n复制、粘贴是有时会报错clipboard: error invoking wl copy/paste failed to connect to a wayland server，去/usr/bin将wl-ccopy和wl-paste删除即可。注：这与Wayland协议（用于ssh等场景）有关。\n\n","categories":["实践指南","大东西","wsl"],"tags":["工具","终端","实践","记录","x-cmd","wsl","Debian","nushell","brew"]}]