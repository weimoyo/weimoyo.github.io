---
title: 大模型学习笔记（二）—-其它知识点总结
date: 2025-08-16 13:56:48
categories: [笔记, LLM]
tags: [LLM, 大模型, Transformer, Attention, Tokenizer, Embedding, LM, 知识点， 总结]
cover: https://pub-85c6ace1f3f74dfdbd0f332fbb2c2f97.r2.dev/PicGo/%E7%8C%8E%E5%BE%B7%E5%A4%A7%E6%A1%A5&%E5%B9%BF%E5%B7%9E%E5%A1%94%E2%80%94%E2%80%94%E5%B9%BF%E5%B7%9E.jpg
series: 大模型学习笔记
katex: true
---

## 如何让模型学习、理解自然语言和世界知识

### 任务设计

1. **去噪自监督学习(Denoising Auto-Encoding)**：破坏原文，让模型补充，BERT的MLM(Masked Language Modeling)就是这种任务。
    **示例:**
    **原文:** The chef cooked the meal.
    **破坏后**: The chef [mask] the meal.
    **主模型的任务:** 预测被 [mask] 替换的词是 cooked。
2. **自回归语言建模 (Autoregressive Language Modeling)**：让模型从左到右逐个预测下一个词。
    **示例:**
    **输入:** 今天天气真不错，我们一起去
    **模型的目标:** 预测出下一个词是 公园、散步 或其他合理的词。
    **学习到的能力:** 这种方法极大地锻炼了模型的生成能力、流畅性和上下文关联能力。因为它必须根据已经出现的所有前文来推断最合理地延续，所以它对语境的理解非常深刻，这也就是为什么GPT系列擅长对话、写作和上下文学习(In-context Learning)。
3. **对比学习 (Contrastive Learning)**：要求模型学会判断“相似”与“不相似”，将向量空间中向量的相似性对齐到自然语言的相似性。
    **示例:**
    **正样本对:** 今天天气真好, 今天是个大晴天 -> 模型需要让这两个句子的向量表示尽可能接近。
    **负样本对:** 今天天气真好, 我的手机没电了 -> 模型需要让这两个句子的向量表示尽可能疏远。
    **学习到的能力:** 这种方法特别擅长学习句子的整体语义表示。训练出的模型在语义搜索、文本匹配、文本聚类等任务上效果极佳，因为它能生成高质量的“句向量”。
4. **下一句预测 (NSP) / 句子顺序预测 (SOP)**：给模型两个句子，让它判断这两个句子在原文中是否是连续的（NSP），或者判断它们的顺序是否正确（SOP）。
    **示例 (NSP):**
    **输入:** A: 我喜欢看电影。 B: 尤其是科幻片。 -> 模型应判断 B 是 A 的下一句。
    **输入:** A: 我喜欢看电影。 B: 香蕉是一种水果。 -> 模型应判断 B 不是 A 的下一句。
    **学习到的能力:** 这种方法让模型学习篇章结构、逻辑连贯性和话题流转，提升了对段落级别语义的理解。
5. **替换词元检测 (Replaced Token Detection - RTD)**：不用 [MASK] 标签去遮盖词，而是用一个小的“生成器”模型生成一个看起来合理但却是错误的词来替换原文的词。然后让主模型（“判别器”）去判断每个词是原文中的真词还是被替换掉的假词。
    **示例:**
    **原文:** The chef cooked the meal.
    **生成器替换后:** The chef **ate** the meal.
    **主模型的任务:** 逐词判断，并指出 ate 是一个被替换的词。
    **学习到的能力:** 因为模型需要对每个词都进行判断，而不是只预测少数几个被遮盖的词，所以训练效率（样本利用率）大大提高。它能让模型学会辨别非常细微的语义和搭配差异。

| 方法 | 核心思路 | 示例 | 学习到的能力 |
|------|----------|------|--------------|
| 去噪自监督学习| 破坏原文，让模型补充 | The chef [mask] the meal. → 预测 cooked | 学习词级语义补全，理解局部上下文 |
| 自回归语言建模 | 从左到右逐词预测下一个词 | 今天天气真不错，我们一起去 → 预测 公园/散步 | 提升生成能力、流畅性、上下文理解，擅长写作和对话 |
| 对比学习 | 判断相似与不相似 | 正样本: 今天天气真好, 今天是个大晴天<br>负样本: 今天天气真好, 我的手机没电了 | 学习句子整体语义表示，适合语义搜索、文本匹配、聚类 |
| 下一句/句子顺序预测 | 判断句子是否连续或顺序是否正确 | A: 我喜欢看电影。 B: 尤其是科幻片。 → 连续<br>A: 我喜欢看电影。 B: 香蕉是一种水果。 → 不连续 | 理解篇章结构、逻辑连贯性和话题流转，提升段落语义理解 |
| 替换词元检测 | 用生成器替换部分词，让主模型判别 | The chef **ate** the meal. → 判别 ate 是否被替换 | 提升训练效率和语义辨别能力，理解细微语义和搭配差异 |

### 超长输入文本的处理方式

1. 高效注意力机制 (Efficient Attention)
    这是解决**“算法瓶颈”**问题的关键。
    *   **传统方式**：标准的自注意力机制，要求文本中每个词都要和其他所有词进行比较，计算量与文本长度的平方 ($O(N^2)$) 成正比，处理长文本时会发生计算爆炸。
    *   **高效方式**：采用多种优化的注意力变体，打破 $O(N^2)$ 的魔咒。核心思想是“不必让每个词都看遍所有词”。
        *   **稀疏注意力 (Sparse Attention)**：只计算最重要的词之间的关联。
        *   **滑动窗口 (Sliding Window)**：只关注每个词邻近的上下文。
        *   **线性化 (Linearization)**：通过数学近似，将计算复杂度降至与文本长度成正比 ($O(N)$)。
    *   **效果**：让模型能在大规模文本中，以极高的效率建立起关键信息之间的长距离联系。
2. 外部系统架构的优化：现实系统会结合检索增强（RAG / Retrieval-Augmented Generation）。

### 大模型的可解释性

#### Mechanistic Interpretability（机械可解释性）

* 传统的可解释性 (Traditional Interpretability)：我们通过给它输入各种问题（prompt），然后观察它的输出（response）来猜测它的功能。
* Mechanistic Interpretability（机械可解释性）：我们不应再把大模型看作一个无法理解的“黑箱”，而是要像拆解一台精密机器或解剖一个大脑一样，去反向工程（reverse-engineer）其内部的每一个组件和连接，精确地找出模型为了完成特定任务而自发学习到的“算法”或“神经回路”。
    研究人员已经取得了一些惊人的发现，例如：
    1.  **间接对象识别回路 (Indirect Object Identification Circuit)**：
        *   在一个经典的研究中，研究者们找到了一个能精确解释模型如何完成以下任务的回路。
        *   句子：“当John和Mary走到商店时，John把一本书递给了__”
        *   模型能准确预测下一个词是“Mary”。MI研究者们通过追踪，发现了一个由几个特定注意力头组成的“电路”。这个电路的功能是：
            1.  找到句子中所有的人名（“John”, “Mary”）。
            2.  识别出最后一个动词的主语（“John”）。
            3.  抑制（忽略）这个主语。
            4.  将注意力集中在剩下的人名（“Mary”）上，从而输出正确答案。
        *   他们不仅发现了这个回路，还能通过人为“干预”（比如禁用其中一个注意力头）来精确地破坏这个功能，从而证明了他们的发现。
    2.  **事实关联与检索**：
        *   模型如何“记住”埃菲尔铁塔在巴黎？MI试图找到存储“埃菲尔铁塔”概念的神经元，以及存储“巴黎”概念的神经元，并找出它们之间是如何通过特定的连接来表示“位于”这个关系的。
    3.  **更复杂的功能**：
        *   研究人员正在尝试寻找更高级的回路，比如模型是如何进行逻辑推理、识别代码中的bug，甚至是模型可能存在的**欺骗行为**（Deception）的回路。

### 数据存储与查询

#### 知识图谱

它的最基本组成单位是三元组（Triple），即：（实体, 关系, 实体） 或者 （实体, 属性, 属性值）。目前常用大模型构建。